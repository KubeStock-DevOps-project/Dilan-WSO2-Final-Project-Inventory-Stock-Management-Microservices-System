# Ansible Automation - Kubernetes Installation

This directory contains Ansible playbooks to install **self-managed Kubernetes** on infrastructure provisioned by Terraform.

## ğŸ“‹ Supported Distributions

- **k3s** - Lightweight, easy to manage (recommended for most use cases)
- **kubeadm** - Standard Kubernetes distribution
- **RKE2** - Rancher's secure, hardened Kubernetes

## ğŸš€ Quick Start

### Prerequisites

1. **Terraform** infrastructure already provisioned
2. **Ansible** >= 2.10 installed
3. **SSH access** to nodes (key configured in Terraform)

### Step 1: Install Ansible

```bash
# Ubuntu/Debian
sudo apt update
sudo apt install -y ansible

# macOS
brew install ansible

# Python pip
pip3 install ansible
```

### Step 2: Verify Inventory

Terraform automatically generates the inventory file:

```bash
cat inventory/hosts.ini
```

You should see master and worker nodes listed.

### Step 3: Test Connectivity

```bash
ansible -i inventory/hosts.ini all -m ping
```

All nodes should respond with `pong`.

### Step 4: Run Playbook

Choose your Kubernetes distribution:

**Option A: K3s (Recommended)**
```bash
ansible-playbook -i inventory/hosts.ini playbooks/install-k3s.yml
```

**Option B: Kubeadm (Standard K8s)**
```bash
ansible-playbook -i inventory/hosts.ini playbooks/install-kubeadm.yml
```

**Option C: RKE2 (Secure K8s)**
```bash
ansible-playbook -i inventory/hosts.ini playbooks/install-rke2.yml
```

Installation takes 5-15 minutes depending on cluster size.

## ğŸ¯ What The Playbooks Do

### install-k3s.yml

1. **Master Setup**
   - Install k3s server
   - Initialize cluster
   - Generate node token
   - Export kubeconfig

2. **Worker Setup**
   - Install k3s agent
   - Join cluster using token
   - Configure networking

3. **Verification**
   - Check node status
   - Verify cluster health

### install-kubeadm.yml

1. **All Nodes**
   - Install Docker/containerd
   - Install kubeadm, kubelet, kubectl
   - Configure kernel parameters

2. **Master Setup**
   - Initialize cluster with kubeadm
   - Install Calico network plugin
   - Generate join command

3. **Worker Setup**
   - Join cluster using kubeadm
   - Configure kubelet

4. **Verification**
   - Check nodes are Ready
   - Verify pod networking

### install-rke2.yml

1. **Master Setup**
   - Install RKE2 server
   - Configure TLS SAN
   - Generate node token

2. **Worker Setup**
   - Install RKE2 agent
   - Join cluster

3. **Verification**
   - Check cluster health
   - Verify security policies

## ğŸ“ Directory Structure

```
ansible/
â”œâ”€â”€ inventory/
â”‚   â””â”€â”€ hosts.ini              # Auto-generated by Terraform
â”œâ”€â”€ group_vars/
â”‚   â””â”€â”€ all.yml               # Auto-generated cluster variables
â””â”€â”€ playbooks/
    â”œâ”€â”€ install-k3s.yml       # K3s installation
    â”œâ”€â”€ install-kubeadm.yml   # Kubeadm installation
    â””â”€â”€ install-rke2.yml      # RKE2 installation
```

## ğŸ”§ Post-Installation

### Get Kubeconfig

Kubeconfig is automatically saved to:
```bash
export KUBECONFIG=../terraform/kubeconfig
kubectl get nodes
```

Expected output:
```
NAME           STATUS   ROLES                  AGE   VERSION
k8s-master-1   Ready    control-plane,master   5m    v1.28.5+k3s1
k8s-worker-1   Ready    <none>                 4m    v1.28.5+k3s1
k8s-worker-2   Ready    <none>                 4m    v1.28.5+k3s1
```

### Verify Cluster

```bash
# Check nodes
kubectl get nodes -o wide

# Check system pods
kubectl get pods -n kube-system

# Check cluster info
kubectl cluster-info
```

### Install Additional Components

```bash
# Install ingress controller
kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/deploy/static/provider/cloud/deploy.yaml

# Install metrics server
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
```

## ğŸ“ Comparison: K3s vs Kubeadm vs RKE2

| Feature | K3s | Kubeadm | RKE2 |
|---------|-----|---------|------|
| **Installation Time** | 5 min | 10-15 min | 10 min |
| **Memory Usage** | Low (512MB+) | Medium (2GB+) | Medium (1GB+) |
| **Complexity** | Simple | Moderate | Moderate |
| **Security** | Good | Good | Excellent |
| **Production Ready** | âœ… | âœ… | âœ… |
| **Best For** | Dev, Edge, IoT | Standard deployments | Regulated industries |
| **Built-in** | SQLite | etcd | etcd |
| **Hardening** | Basic | Manual | Built-in |

### When to Use Each

- **K3s**: Fast setup, resource-constrained, edge computing, dev/test
- **Kubeadm**: Standard K8s, certification requirements, maximum compatibility
- **RKE2**: Security compliance (CIS benchmarks), government, finance, healthcare

## ğŸ”’ Security Considerations

### K3s Security

```bash
# K3s uses secure defaults:
- Automatic TLS certificate rotation
- Built-in network policies
- Minimal attack surface
```

### Kubeadm Hardening

```bash
# Apply CIS benchmarks
kubectl apply -f https://raw.githubusercontent.com/aquasecurity/kube-bench/main/job.yaml

# Enable audit logging
# Enable Pod Security Standards
```

### RKE2 Security

```bash
# RKE2 is CIS hardened by default
- FIPS 140-2 compliance
- SELinux support
- Automatic security updates
```

## ğŸ› Troubleshooting

### Issue: Ansible cannot connect to nodes

**Solution:**
```bash
# Test SSH manually
ssh -i ~/.ssh/your-key.pem ubuntu@<node-ip>

# Check Ansible connectivity
ansible -i inventory/hosts.ini all -m ping -vvv
```

### Issue: Playbook fails during installation

**Solution:**
```bash
# Check node preparation
ansible -i inventory/hosts.ini all -m shell -a "systemctl status kubelet"

# Verify firewall rules
ansible -i inventory/hosts.ini all -m shell -a "iptables -L"

# Check logs
ansible -i inventory/hosts.ini master -m shell -a "journalctl -u k3s -n 50"
```

### Issue: Nodes not joining cluster

**Solution:**
```bash
# Verify master is accessible
curl -k https://<master-ip>:6443/healthz

# Check token
cat /var/lib/rancher/k3s/server/node-token

# Re-run worker playbook
ansible-playbook -i inventory/hosts.ini playbooks/install-k3s.yml --tags worker
```

### Issue: Pods not scheduling

**Solution:**
```bash
kubectl describe node <node-name>
kubectl get pods -n kube-system
kubectl logs -n kube-system <pod-name>
```

## ğŸ“š Advanced Usage

### High Availability (3 Masters)

Set in Terraform:
```hcl
master_node_count = 3
```

Then run playbook - it automatically configures HA.

### Custom Network Plugin

Edit `group_vars/all.yml`:
```yaml
network_plugin: "calico"  # Options: calico, flannel, weave, cilium
```

### Upgrade Cluster

```bash
# K3s upgrade
ansible -i inventory/hosts.ini all -m shell -a "k3s-upgrade.sh"

# Kubeadm upgrade
kubectl drain <node> --ignore-daemonsets
apt-mark unhold kubeadm && apt-get update && apt-get install -y kubeadm=1.29.0-00
kubeadm upgrade apply v1.29.0
apt-mark unhold kubelet kubectl && apt-get install -y kubelet=1.29.0-00 kubectl=1.29.0-00
kubectl uncordon <node>
```

## ğŸ“Š Monitoring Installation

```bash
# Watch nodes joining
watch kubectl get nodes

# Monitor pod status
watch kubectl get pods -A

# Check events
kubectl get events -A --sort-by='.lastTimestamp'
```

## ğŸ¯ Next Steps

After successful installation:

1. **Apply your application manifests**
   ```bash
   kubectl apply -f ../../k8s/base/
   ```

2. **Install ArgoCD for GitOps**
   ```bash
   kubectl apply -f ../../k8s/argocd/
   ```

3. **Set up monitoring**
   ```bash
   kubectl apply -f ../../k8s/monitoring/
   ```

4. **Configure logging**
   ```bash
   kubectl apply -f ../../k8s/logging/
   ```

5. **Apply security policies**
   ```bash
   kubectl apply -f ../../k8s/security/
   ```

## ğŸ¤ Support

For issues:
1. Check playbook output for errors
2. Review `/var/log/syslog` on nodes
3. Check Kubernetes logs: `kubectl logs -n kube-system <pod>`
4. Enable verbose mode: `ansible-playbook -vvv`

---

**Maintained by:** DevOps Team
**Last Updated:** 2025-11-29
